{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Known Keyword Extracton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from urllib.request import Request, urlopen\n",
    "from tldextract import extract\n",
    "import progressbar\n",
    "import pandas as pd\n",
    "import certifi\n",
    "from fake_useragent import UserAgent\n",
    "import requests\n",
    "import warnings\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import ast\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ua = UserAgent()\n",
    "header = {'User-Agent':str(ua.chrome)}\n",
    "\n",
    "links_substring_blacklist = [\n",
    "    'sitemap',\n",
    "    'terms',\n",
    "    'contact',\n",
    "    'careers',\n",
    "    'uploads',\n",
    "    'policy',\n",
    "    '/media',\n",
    "    'events/',\n",
    "    '.jpg',\n",
    "    '.png',\n",
    "    '.pdf'\n",
    "]\n",
    "keywords_limit = 15\n",
    "crawl_limit = 30\n",
    "\n",
    "def link_from_same_subdomain(url, domain):\n",
    "    _, sub_hostname, sub_suffix = extract(url)\n",
    "    _, hostname, suffix = extract(domain)\n",
    "    \n",
    "    return sub_hostname == hostname and sub_suffix == suffix\n",
    "\n",
    "def get_text_from_url(url):\n",
    "    print(f\"getting text from url {url}\")\n",
    "    try:\n",
    "        html_page = requests.get(url, headers=header, verify=False, timeout=10).content\n",
    "    except Exception as e:\n",
    "        print(f'Failed to fetch {url}, {e}\\n')\n",
    "        return \"\"\n",
    "\n",
    "    soup = BeautifulSoup(html_page, 'html.parser')\n",
    "    text = soup.find_all(text=True)\n",
    "\n",
    "    for elem in soup.find_all(['script', 'li', 'header', 'noscript', 'h1', 'h2', 'h3', 'h4']):\n",
    "        elem.decompose()\n",
    "\n",
    "    strips = list(soup.stripped_strings)\n",
    "    \n",
    "    return '\\n'.join([f' {strip} ' for strip in strips if len(strip) > 50])\n",
    "\n",
    "def get_links_from_url(url):\n",
    "    try:\n",
    "        print(f\"getting links url {url}\")\n",
    "        html_page = requests.get(url, headers=header, verify=False, timeout=10).content\n",
    "    except Exception as e:\n",
    "        print(f'Faile to fetch {url} {e}\\n')\n",
    "        return set()\n",
    "\n",
    "    soup = BeautifulSoup(html_page, \"lxml\")\n",
    "\n",
    "    # get all links with absolute paths\n",
    "    links = set()\n",
    "    for link in soup.findAll('a'):\n",
    "        link_href = urljoin(url, link.get('href'))\n",
    "        parsed = urlparse(link_href, scheme='https')._replace(fragment=\"\")\n",
    "        \n",
    "        if parsed.scheme[:4] == 'http':\n",
    "            links.add(parsed.geturl().rstrip('/'))\n",
    "\n",
    "    # return urls with same base domain\n",
    "    return {link for link in links if link_from_same_subdomain(link, url)}\n",
    "\n",
    "def get_links_recursive(url, existing_links=set(), max_depth=1, maxlen=20):\n",
    "    if (len(existing_links) >= max_depth):\n",
    "        return set()\n",
    "\n",
    "    links = get_links_from_url(url)\n",
    "    \n",
    "    existing_links = existing_links | {url}\n",
    "    for link in links - existing_links:\n",
    "        links |= get_links_recursive(link, existing_links)\n",
    "        \n",
    "    for blacklisted_domain_substring in links_substring_blacklist:\n",
    "        links = [link for link in links if blacklisted_domain_substring not in link]\n",
    "    \n",
    "    return links\n",
    "\n",
    "def get_text_from_website(website):\n",
    "    text = ''\n",
    "    for link in get_links_recursive(website)[:crawl_limit]:\n",
    "        text += get_text_from_url(link) + '\\n'\n",
    "        \n",
    "    return text.replace('.', ' ').lower()\n",
    "\n",
    "def get_known_keywords_for_website(website):\n",
    "    print(f\"printing {website}\")\n",
    "    print(f\"printing {website}\")\n",
    "    try:\n",
    "        text = get_text_from_website(website)\n",
    "        known_keywords = pd.read_csv('known_keywords.csv').drop_duplicates()\n",
    "        known_keywords['keyword'] = known_keywords['keyword'].str.lower()\n",
    "        known_keywords['counts'] = known_keywords['keyword'].map(lambda x: text.count(f' {x.strip()} '))\n",
    "        known_keywords['keyword_word_count'] = known_keywords['keyword'].map(lambda x: len(x.split(' ')))\n",
    "\n",
    "        keyword_counts = known_keywords[known_keywords['counts'] > 0]\n",
    "        keyword_counts = keyword_counts.sort_values(by=['keyword_word_count', 'counts'], ascending=False)\n",
    "\n",
    "        return keyword_counts['keyword'].tolist()[:keywords_limit]\n",
    "    except Exception as e:\n",
    "        print(f'got an error with parsing {website}. Skipping. {e}')\n",
    "        return []\n",
    "\n",
    "def get_title(url):\n",
    "    _, hostname, suffix = extract(url)\n",
    "    return hostname.capitalize()\n",
    "\n",
    "safe_url_path = lambda url: \"keywords_parts/\" + re.sub(r'\\W+', '', url)\n",
    "\n",
    "def get_known_keywords_for_website_parallel(url):\n",
    "    keywords_part_path = safe_url_path(url)\n",
    "    if os.path.exists(keywords_part_path):\n",
    "        #print(f\"skipping, {keywords_part_path} already exists\")\n",
    "        return []\n",
    "    else:\n",
    "        keywords = get_known_keywords_for_website(url)\n",
    "        with open(keywords_part_path, 'wb') as fp:\n",
    "            pickle.dump(keywords, fp)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and process domains from domains.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = pd.read_csv('domains.csv')\n",
    "domains[\"domain\"] = domains[\"url\"].map(lambda x: urlparse(x).scheme + '://' + urlparse(x).netloc)\n",
    "domains = domains[[\"domain\"]].drop_duplicates()\n",
    "\n",
    "urls = domains[\"domain\"]\n",
    "print(urls.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform hierarchical website scrapoing traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pool = multiprocessing.Pool()\n",
    "pool.map(get_known_keywords_for_website_parallel, urls)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dataframe with extracted keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_keywords = []\n",
    "for url in urls:\n",
    "    with open(safe_url_path(url), \"rb\") as f:\n",
    "        keywords = pickle.load(f)\n",
    "    extracted_keywords.append({\n",
    "        'domain': url,\n",
    "        'keywords': keywords,\n",
    "        'company_name': get_title(url)\n",
    "    })\n",
    "\n",
    "extracted_kw = pd.DataFrame(extracted_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_kw = extracted_kw[extracted_kw[\"keywords\"].map(lambda x: len(x)) > 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "\n",
    "blacklist = list()\n",
    "with open(\"domain_blacklist.txt\", \"r\") as f:\n",
    "    blacklist = f.read().splitlines()\n",
    "\n",
    "def filter_domains(domain):\n",
    "    domain = domain.replace('http://', '').replace('https://', '')\n",
    "    for blacklisted_domain in blacklist:\n",
    "        if fnmatch.fnmatch(domain, blacklisted_domain):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_kw_list = extracted_kw[extracted_kw['domain'].map(filter_domains)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_kw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_kw_list.to_csv(\"extracted_keywords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unknown Keywords Extraction (POC use case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting links url https://www.lonza.com\n",
      "getting text from url https://www.lonza.com/news-and-media/image-library\n",
      "getting text from url https://www.lonza.com/public/conditions\n",
      "getting text from url https://www.lonza.com/company-overview/our-history\n",
      "getting text from url https://www.lonza.com/news-and-media/a-view-on-podcast\n",
      "getting text from url https://www.lonza.com/news-and-media/leadership-portraits\n",
      "getting text from url https://www.lonza.com/company-overview/leadership\n",
      "getting text from url https://pharma.lonza.com\n",
      "getting text from url https://www.lonza.com/news-and-media\n",
      "getting text from url https://www.lonza.com/investor-relations/shareholders-and-stock-information\n",
      "getting text from url https://www.lonza.com/sustainability/people\n",
      "getting text from url https://www.lonza.com/company-overview/our-locations\n",
      "getting text from url https://www.lonza.com/sustainability\n",
      "getting text from url https://www.lonza.com/news-and-media/news-archive\n",
      "getting text from url https://www.lonza.com/company-overview/strategy\n",
      "getting text from url https://www.lonza.com/news-and-media/logo-guidelines\n",
      "getting text from url https://www.lonza.com/investor-relations/corporate-governance\n",
      "getting text from url https://www.lonza.com/company-overview/our-websites\n",
      "getting text from url https://www.lonza.com/sustainability/performance\n",
      "getting text from url https://www.lonza.com/sustainability/global-quality\n",
      "getting text from url https://www.lonza.com/investor-relations/reporting-center\n",
      "getting text from url https://www.lonza.com/sustainability/ethics-and-compliance\n",
      "getting text from url https://www.lonza.com/company-overview\n",
      "getting text from url https://www.lonza.com/sustainability/planet\n",
      "getting text from url https://www.lonza.com/events\n",
      "getting text from url https://www.lonza.com/news-and-media/blog\n",
      "getting text from url https://www.lonza.com/sustainability/community\n",
      "getting text from url https://www.lonza.com/news-and-media/videos\n",
      "getting text from url https://pharma.lonza.com:443\n",
      "getting text from url https://www.lonza.com/investor-relations\n",
      "getting text from url https://www.lonza.com/investor-relations/agenda-and-events\n"
     ]
    }
   ],
   "source": [
    "text = get_text_from_website(\"https://www.lonza.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POC Example: Perform new keywords discovery from www.lonza.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(cell, patient-scale cell, patient-scale cell, patient-scale cell, calcium, nitrogen, ammonia, calcium, nitric acid, naphtha, niacin, vitamin, joint, niacinamide, mammalian cell cultures, mammalian cell culture, ucb, arabinogalactan, high-growth, u s, cerium, hydro-québec, isophthalic acid, amaxa  , amaxa, line, cell, joint, cell, l-carnitine, vitamin, gmp, glaxosmithkline, gsk, slough, cgmp, vitamin b3  , vitamin b3, human, mesoblast, mesoblast, stem cell, arch, gmp, gmp, urethanes, sartorius stedim, cell, sartorius stedim, niacinamide, wood, slough, hepatocyte, platinum, joint, retinal, l-asparaginase, patient, capsule, 3d, cannabinoids  , cancer  , cancer, cells, patients, antibody-drug, tumors, tumor cells, cancer cells, cells, patients, bioconjugates, bioconjugates, antibody-drug conjugates, vaccine conjugates, cells, cellular, cancerous cells, tumor, cell, tumor cells, cancer, patient, swiss, swiss, eth, human, chro, cell, cell, bioconjugates, cell, patients, cgmp, cell, cell, cocoon, cell, patients, 4d-nucleofector cell, non-viral cell, cell, network  , “, people, water, water, capsule, titanium dioxide-free, titanium dioxide-free, capsule, bispecific antibody, cis-targeted il-2, cis-targeted il-2, cell, cocoon, cell, cell, inhaled, nasal, seufert, seufert, ovarian cancer, cgmp, network, cd34+, mouse, human cord blood cd34+ hematopoietic stem cells, cd34+ cell, myeloma, myeloma, cer, cer1, cocoon, cocoon, patients, swiss, dna, head, kerstin meinecke, swiss, cell, l-carnitine, swiss, cell, faq, water, c, water, people, by-products, iso, ema, gmp, gmp, people, layer, patients, people, chf 1 7, full-year, patients, human, cell, philadelphia  , 27th, cell, cell, cell, heart, lungs, ddl, pulmonary, nasal, cell, people, line, cell, bioconjugates, cell, patients, cgmp, cell, cell, cocoon, cell, patients)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "text = get_text_from_website(\"https://www.lonza.com\")\n",
    "\n",
    "nlp = spacy.load(\"en_ner_bionlp13cg_md\")\n",
    "doc = nlp(text)\n",
    "\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Keywords Extraction POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "text = \"\"\n",
    "with open(\"../mr.pdf\",mode=\"rb\") as in_file:\n",
    "    pdf_reader = PyPDF2.PdfFileReader(in_file)\n",
    "    the_number_of_pages = pdf_reader.getNumPages()\n",
    "    for i in range(the_number_of_pages):\n",
    "        page = pdf_reader.getPage(i)\n",
    "        text += page.extractText() + \"\\n\"\n",
    "        \n",
    "import re\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "text = re.sub(' +', ' ', text)\n",
    "text = text.replace(\"dsad\", \" \").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sgs analytic s switzerland ag dr. stephan pelser ; dr . bernhar dschnu rr lifesciences life i nspir ed, quali ty dri ven 2 © s gs s a 2 0 2 0 a ll righ ts rese rve d sgs in brief testingandce rtifica tionco mpanyre now nedfor havingthehighestsc ientificandcompliance stand ar ds. \\x0bù \\x0bù \\x0bù address: 1 place des alpes ch - 1211 geneva switzerland 3 © s gs s a 2 0 2 0 a ll righ ts rese rve d hea lt hscien cenet work dr ugdev elo pme nt am e r i c as e u r o p e as i a c an ad a toronto ( m a r k h a m , o n ) toronto ( m i s s i s s a u g a , o n ) u s a c h i c a g o ( l i n c o l n s h i r e , il) n e w j ersey ( f air f ield , n j ) p h i l a d e l ph i a ( w es tches ter , pa) b e l g i u m b r u s s e l s ( w avr e ) b r u s s e l s ( z e l l i k ) f r an c e pari s ( v i l l e n e u v e - l a - g a r e n n e ) poi ti ers g e r m an y b e r l i n frank fur t ( t aunus s tein) w i e s b a d e n a a c h e n ( s yn l a b ) b e r l i n ( s yn l a b ) m a r k k l e e b e r g ( s yn l a b ) s w i t z e r l an d g e n e v a b a s e l ( b i r s f e l d e n ) u n i t e d k i n g d o m g l a s g o w i r e l an d c o r k ( r i n g a s k i d d y ) china s h a n g h a i i n d i a n a v i - m u m b a i ex i s ti ngsgs network rec entac qui s i ti ons 4 © s gs s a 2 0 2 0 a ll righ ts rese rve d map ping capabi li ti es europe asi a countr y franc e belgium swit z erland china small molec ules / pepti des \\x01ﬂ \\x01ﬂ \\x01ﬂ \\x01ﬂ biot herapeutic s \\x01ﬂ ( \\x01ﬂ ) \\x01ﬂ \\x01ﬂ cell & gene therapies , cart - t ( \\x01ﬂ ) mrna \\x01ﬂ biomark ers (s oluble) \\x01ﬂ \\x01ﬂ \\x01ﬂ \\x01ﬂ biomark ers (c ellular), funct ional ass ays \\x01ﬂ ( \\x01ﬂ ) bioanalyt ic al monit oring \\x01ﬂ © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a site char ac teristics 48employees 1, 620s qminnewly buildfac ilit y analyt ic alservic esacros s allphas esof clinicalresearchand drugdevelopment i ns t rumentalbioanalys is (lc - ms/ ms) i mmunological& cellularbioanalys is gmp, glp, gcp, i so17025 us - fdaregis t eredandins pec t ed(gmp/ glp) an alyt ic al me thod lifecy cle as s aydevelopment / met hodtrans f er/ training as s ayopt imiz at ion& validat ion samplemeas urement (largesc aleclinic alst udies ) dat areport ing(cus t omiz eddat atrans f er) st orageof samples (remot econt rol24/ 7) synlaba & s switzerland ag, part of sgs since 01 jan21 © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a aeraofexpertise discover y pharmacol og y pk bi oanal yti c s (pharmac euti c al s & b i opharmac euti c al s ) fasttat, any m atric es pre - clini cal & cli ni caldevelo pment pk bi oanal yti c s (pharmac euti c al s & b i opharmac euti c al s ) determi nati on of m etabol i tes (pharmac euti c al s ) im m unogeni c i ty:ada , nab (bi opharmac euti c al s ) drug develop ment (biop harmaceuticals) pote nc yas s ays (releas e & s tabi l i ty) quali ty control (releas e & s tabi l i ty / characte riz ati on) © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a quality managementsy s tems gl p/g mpcertified qa manag ement (qp/ftvp) (gmp ) internal qau (glp) europ ean and u.s. stand ards gmp: eu - gmp guide / ichq7a / fda 21 cfr 210/211 glp: oecd gui del i nes (series of princ i pl es of glp) gcp: reflec ti on paper in spection sandaud its swi s s medic (swi s s national health authori ty) /oecd fda (fda regis tered) cus tomers iso 17025, accreditatio n in july 2017 trackwise digi tal( eqms ):go li ve july 2021! © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a global qualitysystem globalqualit y m anual qdc - 000008 global pol i ci es global sops ot herglobal documents (fo rm s,w i,qu a lity a gree m e n ts, e tc) guidancedoc ument t hat des c ribesageneralproc es st hat is implement edin evaluated and implementedv ialocalsop gsops t obeus ed sit es c anhav ealoc alw i f ors upporting ins t ruc tionif deemednec es s ary(ins t ructionregardingloc allogbookset c . , ) s y s t eminordert oprov idequalit y s erv ic es groupedunderdif f erentt y peof doc uments wit hint hee - dms modules upport globaldoc umentation&operations impac t ingt heglobaland/orloc alt eams . global procedures and policies are in place to harmonise and standardise activities across sbu t hey are regularly updated in response to regulatory changes, observations and changes in t he network © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a quality managementsystems si te co u n try q ms u sfda fei n o. u sfda i nspected c hica go (lincolnshir e ) u sa g mp / g lp/ iso 9001 1418028 \\x066 ne w j e rse y(fa irfie ld) g mp / iso 9001 2214690 \\x066 phila de lphia (west c he ster) g mp 1000307080 \\x066 toronto (missi ssa uga) canada g mp / iso 9001/iso 13485 3007632373 \\x066 toronto (ma rkha m) g mp 3005630028 \\x066 b russe ls( wa v re ) belgi um g mp / g lp/ g cp / iso 17025 283063907 \\x066 b russe ls( ze ll ik ) g mp - - pa ris (vil le ne uv e - la - ga renne ) france g mp 3002807507 \\x066 poitie rs g lp/ g cp 3005865090 \\x066 aache n* g ermany g mp 3014435713 - b e rli n g mp 341259550 \\x066 b e rli n* iso 17025 - - f ra nkfurt( ta unussute in ) g mp / iso 17025 317219699 \\x066 l e ipzig ( ma rkkl e e be rg )* g mp - - wie sba de n g mp - - c ork ( r inga skiddy )* i rel and g mp 3003627233 \\x066 ge ne v a (pla n - le s - oua tes ) sw i t zerland g mp / g lp/ g cp 3002807654 \\x066 b a se l( b irsfe lde n )* g mp / g lp/ iso 17025 3007178576 \\x066 gl a sgow uk g mp / g lp 3009867953 \\x066 na v imumba i i ndi a g mp / iso 17025 650786127 \\x066 s ha nghai china g mp / iso 17025 3007377330 \\x066 * rec e n t a d q u i s i ti o n s © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a organisation (to tal fte 45 an d g ro wing ) tec hni c al operatio ns ma n a ge m ent te stfa cility/s ite ma n a ge m ent(gl p ) / ma n a ge m ent(gmp /i s o) fin a n ce & hr qu a lity ma n a ge men t (gmp /g l p /i s o) b ioa n alytica l te stin g (gl p ) disco ve ry p h a rm a cology p reclinica l a n d clinica ldeve lop m ent qu a lity co n tro l b iolo gics (gmp ) e u r.p h ,<usp >, p u rity , im p u ritie s fu n ctio n al te stin g a d m inistrat ion/a rchive (gmp /g l p /i s o) it & da ta ma n a ge m ent (gmp /g l p /i s o) b u sine ss deve lop m ent/ s ales © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a assay development / method transfer / training assay optimization assay validation sample measurement (large scale clinical studies) data reporting (customized data t ransfer) storage ofsamples (remote control 24/7) collaborations (to extend portf olio) overv iew anaytical services © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a colorimetric (uv/vis) fluorescence fp t rf/ht rf luminescence alphascreen ecl read - ou t systems state - of - the - art facil iti es(bl2) cell culture facilities bioanalytical laboratories storage facilities ( - 80 c; remote control) expertiseand techniques cel l ul ar & imm unol ogi c al bi oanal ys i s © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a state o f th eart facil iti es bioanalytical laboratories storage facilities ( - 80 c; remote control) triple q uadrupole ms high resolution accurate mass ms uv/pda automation analytic al systems expertiseand techniques ins trumental bi oanal ys i s © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a sciex platform ( valid ated and qu alifi ed ): mas s - spec trometer: 1xab sc i ex 5500, 1xab sc i ex 6500 2xab sc i ex 6500+ hplc: shi madzusil - 30ac (mp) i nc ombinati on wi th shi madzulc - 30ad & lc - 20ad th ermof isher platform ( valid ated and qu alifi ed ): mas s - spec trometer: 1xtsq al ti s 4xtsq vantage 4xtsq quantum 1x ltq orbitrap xl hplc: di onex vanqui s hsys tem or ctc dlw - sys tems / therm ofis her - pump automation ( vali dated and qu ali fied ): sam pl e preparati on: tec an & hami l tonsys tem logi s ti c & p roces s i ng: wats on lims v 7.6 equipment: ms - facility © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a imp uriti es : hplc: agi l ent1260 infini ty ii bi oinertwi th 13 µl dad capi l l ary el ec trophoresi s : sc i exbec k mann co ul ter pa800 pl us wi th uv/p dadetec ti on ph ysicochemical properties: os mometer: adv ancedinstrumentad1 os motech turbidi meter: hac htl2350 ph meter: mettl ertol edo s ev en e xc el l enc e dens i ty meter: mettl ertol edo e xc el l enc ed4 uv spectrophotometer: mettlertoledo excel l enceuv/vis spec trophotometer uv7 particul ate matter and other parameters: li qui departi c l ec ounter: bec k mann co ul ter hiac9703+ water ti trator: mettl ertol edoti trator compac t c30sx anal yti c al bal anc e: mettl ertol edo x pr204 , e.g. for extractab l e v ol umes equipment: qc release& stability ( biologics ) © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a t es t nam e requir ed s am ple volum e eur. ph. usp g mp r equierm ents devic es hplc hplc rever s ed phas e/s eize ex c lus ion / ion ex c hange/ hydrophobic inter ac tion / hydrophilic inter ac tion / peptidemap w ithuv and fld detec tion cad detec toris in evaluation f orthe t ween (polys orbate) analys is c a.100 µl n/a pr oduc t s pec if ic so p / validation agilent, inf inity ii bioiner t ce ce cz e / ce - sds / c ief c a.100 µl n/a pr oduc t s pec if ic so p / validation sc iex , pa800+ pr otein sim ple,mauric e c clarity clarity and degr eeof opales c enc eof liquids nephelom etry, t urbidim etry andvis ual c om par is on 2 m l 2.2.1 <855> bas ic c om pendial m ethod hac h,t l2350 color degree of c oloration of liquids color and ac hrom ic ity 2.2.2 <631> bas ic c om pendial m ethod vis ual m ethod i or ins trum ental m ethodii mettler - t oledo,uv7 ph potentiom etric determ inationof ph ph 2.2.3 <791> bas ic c om pendial m ethod mettler - t oledo, s even ex c ellenc e dens ity relative dens ity spec if ic gravity 2.5 ml 2.2.5 <841> bas ic c om pendial m ethod mettler - t oledo,d4 o s om lality o s m olality o s m olality and os m olarity 100µl 2.2.35 <785> bas ic c om pendial m ethod advanc ed ins tr um ents , o s m om eter ad1 uv abs or ption s pec trophotom etry,ultraviolet and vis ible ultr aviolet - vis ible s pec tr os c opy c a.100 µl 2.2.25 <857> pr oduc t s pec if ic so p / validation mettler - t oledo,uv7 kf w ater :s em i - m ir c o determ ination w ater determ ination 2.5.12 <921> pr oduc t s pec if ic so p / validation mettler - t oledo, titr ator c30 ex tr ac table volum e t es tf orex tr ac tablevolum e of par enteralpreparations deter m ination of volum e of inj ec tion in c ontainer s 2.9.17 <1> bas ic c om pendial m ethod mettler - t oledo,x pr204 sub - vis ible partic les partic ulate c ontam ination: s ub - vis ible par tic les partic ulate matter in inj ec tions subvis ible par tic ulate m atterin ther apeutic protein inj ec tions 2 m l 2.9.19 <788> <787> bas ic c om pendial m ethod bec k m an - coulter,hiac9703+ vis ible partic les partic ulate c ontam ination:vis ible par tic les vis ible par tic ulates in inj ec tions 2.9.20 <790> bas ic c om pendial m ethod adelphi , apollo ii liquid viewer t es to , lux m eter ccit rubber c los ures f orpar enteral prepar ations ,f orpowder s and f or f r eeze - dried powder s pac k ageintegrity evaluation s terile produc ts <1207> pr oduc t s pec if ic so p / validation blue dye bath tes t b a sic co m p e ndialm e th o d srequ ire s n e ith e ra va lid a tio n n o ra ve rif icat ion a cco rdin g usp<1 2 2 6 >. p rod u ctsp e cif icco m p e nd ia l m etho ds( e .g. h u m a ninsu lin ) m u stb e ve rif ied . overview of qc - services(phys - che m - ana lytics) © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a fu nctio nal& structural testin g potencyassa ys (cel l based): prolif erat ionas s ay report ergeneas s ay sec ondmes s engers adcc/ cdc/ adcp mas t er/ work ing/ singleus ecellbank s potencyassa ys (i mmunol ogi cal): bindingeli sa competit iveelisa pepti dem apping: hplc/ uhplc, lc - ms/ ms impu rities/ characterizatio n bi ochemi cal&m ol ecul ar m ethods: hos t cellprot ein prot eina hos t celldna (qpcr)* endotoxins chr omatogr aphi cm ethods: hplc/ uhplc ce/ i ef compendi al m ethods(usp/ ph. eur . ): appearance/color ph wat ercont ent part ic ulatemat t er(s ub - vis ible) *at s i te i n be l g i u m services:qc release& stability (i) © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a big pharma medium - sized pharma biotech medical device manufacturers service providers america europe asia clients word - wide © s gss oc iét é générale de s urveil lanc e s a 2020 a ll right s res erved - s gs is a regis t ered t radem ark of s gss oc iét é générale de s urveil lanc e s a thank you for your attention. © sgs gro u p ma n a g e m e n tsa 2020 al l rig h ts res e rve d sgs i s a re g i s te re d tra d e m a rk o f sgs gro u p ma n a g e m e n tsa '"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['validation',\n",
       " 'ms',\n",
       " 'ce',\n",
       " 'qc',\n",
       " 'gmp',\n",
       " 'scale',\n",
       " 'development',\n",
       " 'ad',\n",
       " 'qa',\n",
       " 'clinical',\n",
       " 'sec',\n",
       " 'hplc']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_keywords = pd.read_csv('known_keywords.csv').drop_duplicates()\n",
    "known_keywords['keyword'] = known_keywords['keyword'].str.lower()\n",
    "known_keywords['counts'] = known_keywords['keyword'].map(lambda x: text.count(f' {x.strip()} '))\n",
    "known_keywords['keyword_word_count'] = known_keywords['keyword'].map(lambda x: len(x.split(' ')))\n",
    "\n",
    "keyword_counts = known_keywords[known_keywords['counts'] > 0]\n",
    "keyword_counts = keyword_counts.sort_values(by=['keyword_word_count', 'counts'], ascending=False)\n",
    "\n",
    "keyword_counts['keyword'].tolist()[:keywords_limit]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
